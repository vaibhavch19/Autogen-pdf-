
# ğŸ§  LLM-Powered PDF Summarizer with ChromaDB, Gemini, FastAPI & AutoGen

A powerful, modular PDF summarization system built using **Google Gemini LLM**, **ChromaDB vector search**, **SentenceTransformer embeddings**, **AutoGen agents**, and **FastAPI with WebSocket support**. This tool enables real-time semantic summarization, validation, and refinement of PDF documents using hybrid LLM + retrieval-based techniques.

---

## ğŸš€ Features

- ğŸ” **Semantic Chunk Retrieval via ChromaDB**
- ğŸ§  **LLM-powered summarization using Gemini (AutoGen)**
- ğŸ“ **PDF Text Extraction using pdfplumber**
- âœ‚ï¸ **Chunking with Token Limit Awareness**
- ğŸ” **Summary Refinement with User Feedback**
- ğŸ”„ **Real-time WebSocket Interaction via FastAPI**
- ğŸ§© **Hybrid Search Support (Regex + Semantic Matching)**

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ embedding_model.py     # SentenceTransformer logic
â”œâ”€â”€ pdf_processing/
â”‚   â””â”€â”€ extractor.py           # PDF text extraction & chunking
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ chroma_db.py           # ChromaDB collection creation & querying
â”œâ”€â”€ llm_agents/
â”‚   â””â”€â”€ run_crew.py            # AutoGen Crew & Agents (Gemini)
â”œâ”€â”€ api/
â”‚   â””â”€â”€ server.py              # FastAPI WebSocket Server
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Technologies Used

| Component                | Tech Stack                                      |
|-------------------------|--------------------------------------------------|
| LLM                     | Google Gemini 1.5 Flash via AutoGen              |
| Embeddings              | SentenceTransformer (`all-MiniLM-L6-v2`)        |
| Vector Store            | ChromaDB                                         |
| PDF Text Extraction     | pdfplumber                                       |
| Agent Framework         | AutoGen (AssistantAgent, UserProxyAgent)        |
| Backend API             | FastAPI with WebSocket                          |

---

## ğŸ’¡ How It Works

1. **PDF Uploaded â Text Extracted (via pdfplumber)**
2. **Text â Tokenized & Chunked (~512 tokens)**
3. **Chunks â Embedded using SentenceTransformer**
4. **Embeddings â Stored in ChromaDB**
5. **Query â Embedding â Top-k Similar Chunks Retrieved**
6. **LLM (Gemini) + Retrieved Chunks â Summary Generated**
7. **User Feedback â Summary Refined (via LLM)**

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the repo**
```bash
git clone https://github.com/yourusername/pdf-summarizer-llm.git
cd pdf-summarizer-llm
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set your Gemini API Key**
- Add your API key in `.env` or directly in `run_crew.py`:
```python
config_list = [
    {
        "model": "gemini/gemini-1.5-flash",
        "api_key": "YOUR_GEMINI_API_KEY"
    }
]
```

4. **Run the server**
```bash
python api/server.py
```

---

## ğŸ“¡ WebSocket Workflow

- Client connects via WebSocket.
- Sends PDF and Query.
- Server processes PDF â Embeds â Retrieves â Summarizes â Sends Response.
- User provides feedback â Server refines response.

---

## ğŸ§ª Example Use Case

> _"Upload a contract PDF and ask for a summary of payment terms."_

- System identifies and retrieves relevant sections.
- Gemini summarizes key clauses.
- User can say â€œrefine further focusing on due datesâ€ â Improved summary returned.

---

## ğŸ“Œ Future Enhancements

- âœ… OCR support for scanned/image-based PDFs.
- âœ… Hybrid search: Combine Regex & Embeddings.
- âœ… Export summary as JSON/CSV.
- âœ… RAG pipelines using LangChain.

---

## ğŸ™Œ Acknowledgements

- [AutoGen by Microsoft](https://github.com/microsoft/autogen)
- [Google Gemini API](https://deepmind.google/discover/gemini/)
- [ChromaDB](https://www.trychroma.com/)
- [SentenceTransformers](https://www.sbert.net/)
- [FastAPI](https://fastapi.tiangolo.com/)

---

## ğŸ“„ License

This project is licensed under MIT. Feel free to fork, extend, and contribute.

---

## ğŸ’¬ Feedback & Contributions

Pull requests, feedback, and feature suggestions are welcome! ğŸ™Œ  
Feel free to create issues or contact me via [LinkedIn](https://linkedin.com/in/your-profile).
